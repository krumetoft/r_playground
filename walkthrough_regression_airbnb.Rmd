---
title: "SLICED Season 1 Episode 5 (Practice)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
library(textrecipes)
library(tidytext)
library(scales)
library(stacks)
library(broom)

theme_set(theme_light())
doParallel::registerDoParallel(cores = 4)
```

```{r}
data_link <- "data/sliced-s01e05-WXx7h8/"

dataset <- read_csv(paste(data_link, "train.csv", sep = '')) %>%
  mutate(price = log(price + 1))
holdout <- read_csv(paste(data_link, "test.csv", sep = ''))
read_csv(paste(data_link, "sample_submission.csv", sep = ''))

set.seed(2021)
spl <- initial_split(dataset, .75)
train <- training(spl)
test <- testing(spl)
```


```{r}

predict_holdout <- function(wf){
  wf %>% 
    augment(holdout) %>% 
    mutate(.pred = exp(.pred) - 1) %>% 
    select(id, price = .pred)
}


augment.model_stack <- function(model_stack, data, ...) {
  predictions <- model_stack %>%
    predict(data)
  
  data %>% 
    bind_cols(predictions)
}
```

```{r}
train %>% 
  count(name, sort = T)

summarize_prices <- function(tbl) {
  tbl %>% 
    summarize(avg_price = exp(mean(price)) - 1,
              median_price = exp(median(price)) - 1,
              n = n()
              ) %>% 
    arrange(desc(n))
}

train %>% 
  ggplot(aes(price)) +
  geom_histogram()

train %>% 
  group_by(neighbourhood_group) %>% 
  summarize_prices() %>% 
  mutate(neighbourhood_group = fct_reorder(neighbourhood_group, median_price)) %>% 
  ggplot(aes(median_price, neighbourhood_group)) +
  geom_col()

train %>%
  mutate(neighbourhood_group = fct_reorder(neighbourhood_group, price)) %>%
  ggplot(aes(exp(price), neighbourhood_group)) +
  geom_boxplot() +
  scale_x_log10()

train %>%
  mutate(neighbourhood = fct_lump(neighbourhood, 40),
         neighbourhood = fct_reorder(neighbourhood, price)) %>%
  ggplot(aes(exp(price), neighbourhood)) +
  geom_boxplot() +
  scale_x_log10()

train %>%
  mutate(room_type = fct_reorder(room_type, price)) %>%
  ggplot(aes(exp(price), room_type)) +
  geom_boxplot() +
  scale_x_log10()

train %>%
  mutate(minimum_nights = pmin(minimum_nights, 14)) %>% #caps the feature at 14, cool!
  ggplot(aes(minimum_nights, price, group = minimum_nights)) + #No need to group beforehand
  geom_boxplot()

train %>%
  sample_n(3000) %>%
  ggplot(aes(minimum_nights + 1, price)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method = "loess")

train %>%
  ggplot(aes(reviews_per_month, price)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method = "lm")

train %>%
  ggplot(aes(calculated_host_listings_count, price)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method = "lm")

train %>%
  ggplot(aes(availability_365, price)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method = "lm")
```
```{r}
train %>% 
  unnest_tokens(word, name) %>% 
  group_by(word) %>% 
  summarize_prices() %>% 
  head(50) %>% 
  mutate(word = fct_reorder(word, avg_price)) %>% # tells ggplot the order of the factor is by avg_price
  ggplot(aes(avg_price, word, size = n)) +
  geom_point()

train %>%
  mutate(host_id = factor(host_id)) %>%
  mutate(host_id = fct_lump(host_id, 40)) %>%
  mutate(host_id = fct_reorder(host_id, price)) %>%
  ggplot(aes(price, host_id)) +
  geom_boxplot()

  
```
```{r}
set.seed(2021)
mset <- metric_set(rmse)

grid_control <- control_grid(save_pred = T,
                             save_workflow = T,
                             extract = extract_model
                             )

train_fold5 <- train %>% 
  vfold_cv(5) #allows for a strata argument
```

```{r}
prep_juice <- function(d) juice(prep(d))

# Does not include name, host_id, host_name, neighbourhood
xg_rec <- recipe(price ~ minimum_nights + room_type + number_of_reviews +
                   latitude + longitude + neighbourhood_group +
                   reviews_per_month + calculated_host_listings_count +
                   availability_365 + last_review,
                 data = train) %>%
  #step_log(all_numeric_predictors(), offset = 1) %>%
  step_mutate(is_manhattan = neighbourhood_group == "Manhattan") %>%
  step_rm(neighbourhood_group) %>%
  step_mutate(last_review = coalesce(as.integer(Sys.Date() - last_review), 0)) %>%
  step_dummy(all_nominal_predictors())

xg_mod <- boost_tree("regression",
                     mtry = tune(),
                     trees = tune(),
                     learn_rate = tune()) %>%
  set_engine("xgboost")

xg_wf <- workflow() %>%
  add_recipe(xg_rec) %>%
  add_model(xg_mod)

xg_tune <- xg_wf %>%
  tune_grid(train_fold5,
            metrics = mset,
            control = grid_control,
            grid = crossing(mtry = c(7),
                            trees = seq(250, 1500, 25),
                            learn_rate = c(.008, .01)))

autoplot(xg_tune)

xg_tune %>%
  collect_metrics() %>%
  arrange(mean)

```
```{r}
xg_fit <- xg_wf %>%
  finalize_workflow(select_best(xg_tune)) %>%
  fit(train)

xg_fit %>%
  augment(test) %>%
  rmse(price, .pred)
```

```{r}
importances <- xgboost::xgb.importance(model = xg_fit$fit$fit$fit) #Whoa!

importances %>%
  mutate(Feature = fct_reorder(Feature, Gain)) %>%
  ggplot(aes(Gain, Feature)) +
  geom_col()

```


```{r}
xg_rec %>% 
  prep_juice() %>% 
  ggplot(aes(last_review)) +
  geom_histogram()


```
```{r}

lin_rec <- recipe(price ~ name + room_type +
                    latitude + longitude +
                    neighbourhood_group +
                    neighbourhood +
                    host_id,
                  data = train) %>%
  step_tokenize(name) %>%
  step_tokenfilter(name, max_tokens = tune()) %>%
  step_tf(name) %>%
  step_mutate(host_id = factor(host_id)) %>%
  step_other(host_id, neighbourhood, threshold = tune()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors())

lin_mod <- linear_reg(penalty = tune()) %>%
  set_engine("glmnet")

lin_wf <- workflow() %>%
  add_recipe(lin_rec) %>%
  add_model(lin_mod)

lin_tune <- lin_wf %>%
  tune_grid(train_fold5,
            metrics = mset,
            control = grid_control,
            grid = crossing(penalty = 10 ^ seq(-7, -1, .1),
                            threshold = .001,
                            max_tokens = c(30, 100, 300, 500)))
autoplot(lin_tune)

lin_tune %>%
  collect_metrics() %>%
  arrange(mean)
```


```{r}
lin_fit <- lin_wf %>%
  finalize_workflow(select_best(lin_tune)) %>%
  fit(train)

lin_fit %>%
  augment(test) %>%
  rmse(.pred, price)
```


```{r}
lin_fit
```

A test of RandomForest on Text data
```{r}
rf_mod <- rand_forest(mode = 'regression',
                      trees = 200,
                      mtry = tune(),
                      min_n = tune()
                      ) %>%
  set_engine("ranger")

rf_wf <- workflow() %>%
  add_recipe(lin_rec) %>%
  add_model(rf_mod)

rf_tune <- rf_wf %>%
  tune_grid(train_fold5,
            metrics = mset,
            control = grid_control,
            grid = crossing(mtry = c(9, 12, 15),
                            min_n = c(NULL, 10, 50),
                            threshold = .001,
                            max_tokens = c(500)
                            ))
autoplot(rf_tune)

rf_tune %>%
  collect_metrics() %>%
  arrange(mean)
```

```{r}
rf_fit <- rf_wf %>%
  finalize_workflow(select_best(rf_tune)) %>%
  fit(train)

rf_fit %>%
  augment(test) %>%
  rmse(.pred, price)

```
```{r}
lin_best <- lin_tune %>% filter_parameters(parameters = select_best(lin_tune))
xg_best <- xg_tune %>% filter_parameters(parameters = select_best(xg_tune))
rf_best <- rf_tune %>% filter_parameters(parameters = select_best(rf_tune))

blended_lin_xg <- stacks() %>%
  add_candidates(lin_best) %>%
  add_candidates(xg_best) %>%
  add_candidates(rf_best) %>% 
  blend_predictions()

blended_lin_xg_fit <- blended_lin_xg %>%
  fit_members()


blended_lin_xg_fit %>% 
  augment.model_stack(test) %>% 
  rmse(.pred, price)
```

```

